model:
  target: cldm.cldm.ControlLDM
  params:
    linear_start: 0.00085
    linear_end: 0.0120
    num_timesteps_cond: 1
    log_every_t: 200
    timesteps: 1000
    first_stage_key: "jpg"
    cond_stage_key: "txt"
    control_key: "hint"
    image_size: 64
    channels: 4
    cond_stage_trainable: false
    conditioning_key: crossattn
    monitor: val/loss_simple_ema
    scale_factor: 0.18215
    use_ema: False
    only_mid_control: False

    control_stage_config:
      target: cldm.cldm.ControlNet
      params:
        image_size: 32 # unused
        in_channels: 4
        hint_channels: 3
        model_channels: 320
        attention_resolutions: [ 4, 2, 1 ]
        num_res_blocks: 2
        channel_mult: [ 1, 2, 4, 4 ]
        num_heads: 8
        use_spatial_transformer: True
        transformer_depth: 1
        context_dim: 768
        use_checkpoint: True
        legacy: False

    unet_config:
      target: cldm.cldm.ControlledUnetModel
      params:
        image_size: 32 # unused
        in_channels: 4 #输入通道数，值为4
        out_channels: 4
        model_channels: 320 #模型基础通道数，值为320。这是UNet最开始的特征图通道数，后续层的通道数会基于此值和channel_mult参数进行缩放。
        attention_resolutions: [ 4, 2, 1 ] #注意力机制应用的分辨率，值为[4, 2, 1]。这表示在UNet下采样4倍、2倍和1倍（即原图尺寸）时会应用注意力机制。
        num_res_blocks: 2
        channel_mult: [ 1, 2, 4, 4 ]
        num_heads: 8
        use_spatial_transformer: True
        transformer_depth: 1 #这指定了每个SpatialTransformer块中BasicTransformerBlock的数量
        context_dim: 768
        use_checkpoint: True
        legacy: False #是否使用旧版本，值为False。

    first_stage_config:
      target: ldm.models.autoencoder.AutoencoderKL
      params:
        embed_dim: 4 #在Stable Diffusion中，图像被编码为4通道的潜在表示
        monitor: val/rec_loss #监控指标，用于训练过程中监控验证集的重建损失
        ddconfig:
          double_z: true  #使用变分自编码器（VAE）
          z_channels: 4 # 潜在空间的通道数，与embed_dim保持一致，表示编码后的潜在向量有4个通道。
          resolution: 256 # 输入图像的分辨率，值为256x256
          in_channels: 3  # 输入图像的通道数，值为3
          out_ch: 3 # 输出图像的通道数，值为3
          ch: 128 # 潜在空间编码器的通道数，值为128
          ch_mult: #通道倍增因子，控制网络在不同层级的通道数。值为[1, 2, 4, 8]，表示每经过一层，通道数会乘以相应的倍数。
          - 1
          - 2
          - 4
          - 4
          num_res_blocks: 2
          attn_resolutions: []
          dropout: 0.0
        lossconfig:
          target: torch.nn.Identity

    cond_stage_config:
      target: ldm.modules.encoders.modules.FrozenCLIPEmbedder
